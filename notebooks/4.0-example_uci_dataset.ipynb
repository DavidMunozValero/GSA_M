{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from benchmarks import gsa_svm_fitness\n",
    "from src.entities import GSA\n",
    "\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats as st\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from typing import Mapping, Tuple, Union\n",
    "from ucimlrepo import fetch_ucirepo"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3cc59d5610d418"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "uci_datasets = [\"Breast Cancer Wisconsin (Diagnostic)\",\n",
    "                \"Spambase\",\n",
    "                \"Mushroom\"]\n",
    "\n",
    "widget_opt = widgets.Dropdown(\n",
    "    options=uci_datasets,\n",
    "    description='Dataset: '\n",
    ")\n",
    "\n",
    "display(widget_opt)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8e7510efbb71f63"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def fetch_uci_dataset(dataset_name: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Fetch UCI dataset\n",
    "    \"\"\"\n",
    "    def fetch_categorical_dataset(_id: int) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        data = fetch_ucirepo(id=_id)\n",
    "        X = data.data.features\n",
    "        y = data.data.targets\n",
    "        encoder = LabelEncoder()\n",
    "        for col in X.columns:\n",
    "            X.loc[:, col] = encoder.fit_transform(X[col])\n",
    "        return X, y\n",
    "\n",
    "    if widget_opt.value == \"Breast Cancer Wisconsin (Diagnostic)\":\n",
    "        data = fetch_ucirepo(id=15)\n",
    "        X = data.data.features\n",
    "        y = data.data.targets\n",
    "        X = X.fillna(value=0)\n",
    "    elif widget_opt.value == \"Spambase\":\n",
    "        X, y = fetch_categorical_dataset(_id=94)\n",
    "    elif widget_opt.value == \"Mushroom\":\n",
    "        X, y = fetch_categorical_dataset(_id=73)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = fetch_uci_dataset(widget_opt.value)\n",
    "\n",
    "# Name of selected dataset and summary (number of instances, features, etc.)\n",
    "print(f\"Dataset: {widget_opt.value}\")\n",
    "print(f\"Instances: {X.shape[0]}\")\n",
    "print(f\"Features: {X.shape[1]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "437c2c37bb7e8030"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# WARNING!! GLOBAL VARIABLES\n",
    "wa = 0.0\n",
    "wf = 0.0\n",
    "\n",
    "# IMPORTANT!! MUTABLE GLOBAL VARIABLE\n",
    "conf_matrix_dict = {\"TP\": 0, \"FP\": 0, \"TN\": 0, \"FN\": 0}\n",
    "\n",
    "class UCI:\n",
    "    \"\"\"\n",
    "    Class to handle UCI datasets\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): Features\n",
    "        y (pd.Series): Target\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 X: pd.DataFrame,\n",
    "                 y: pd.Series,\n",
    "                 boundaries: Mapping[str, Tuple[Tuple[float, float], ...]]\n",
    "                 ) -> None:\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \n",
    "        Args:\n",
    "            X (pd.DataFrame): Features\n",
    "            y (pd.Series): Target\n",
    "            boundaries (Mapping[str, Tuple[Tuple[float, float], ...]): Boundaries for the optimization problem\n",
    "            seed (int, optional): Random seed. Defaults to 5.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.boundaries = boundaries\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(self.X)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size = 0.20)\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "    \n",
    "    def get_fitness(self,\n",
    "                    solution: Mapping[str, np.ndarray],\n",
    "                    data: Union[None, Tuple[np.ndarray, np.ndarray]] = None,\n",
    "                    show_confusion_matrix: bool=False\n",
    "                    ) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Get fitness of a solution\n",
    "        \n",
    "        Args:\n",
    "            solution (Mapping[str, np.ndarray]): Solution to evaluate\n",
    "            data (Union[None, Tuple[np.ndarray, np.ndarray]], optional): Data to evaluate the solution. Defaults to None.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[float, float]: Fitness and accuracy of the solution    \n",
    "        \"\"\"\n",
    "        if data is None:\n",
    "            X_scaled = self.X_train\n",
    "            y_data = self.y_train\n",
    "        else:\n",
    "            X_scaled, y_data = data\n",
    "            \n",
    "        gamma, C = solution['real']\n",
    "        gamma /= 1_000\n",
    "        C /= 1_000\n",
    "        X_scaled_filtered = X_scaled[:, solution['discrete'].astype(int) == 1]\n",
    "        svc_model = SVC(gamma=gamma, C=C, kernel=\"rbf\", verbose=False)\n",
    "        svc_model.fit(X_scaled_filtered, np.ravel(y_data))\n",
    "        y_predict = svc_model.predict(X_scaled_filtered)\n",
    "        conf_matrix = confusion_matrix(y_data, y_predict)\n",
    "        if show_confusion_matrix:\n",
    "            # Update global conf_matrix_dict\n",
    "            conf_matrix_dict[\"TP\"] = conf_matrix[0, 0]\n",
    "            conf_matrix_dict[\"FP\"] = conf_matrix[0, 1]\n",
    "            conf_matrix_dict[\"TN\"] = conf_matrix[1, 1]\n",
    "            conf_matrix_dict[\"FN\"] = conf_matrix[1, 0]\n",
    "            print(conf_matrix)\n",
    "        accuracy = accuracy_score(y_data, y_predict) * 100\n",
    "        \n",
    "        return gsa_svm_fitness(accuracy=accuracy, solution=solution, wa=wa, wf=wf)\n",
    "\n",
    "    def is_feasible(self, solution: Mapping[str, np.ndarray]) -> bool:\n",
    "        \"\"\"\n",
    "        Check if a solution is feasible\n",
    "\n",
    "        Args:\n",
    "            solution (Mapping[str, np.ndarray]): Solution to evaluate\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the solution is feasible, False otherwise\n",
    "        \"\"\"\n",
    "        real_values = solution['real']\n",
    "        discrete_values = solution['discrete']\n",
    "\n",
    "        for i, (min_val, max_val) in enumerate(self.boundaries['real']):\n",
    "            if real_values[i] < min_val or real_values[i] > max_val:\n",
    "                return False\n",
    "\n",
    "        for i, (min_val, max_val) in enumerate(self.boundaries['discrete']):\n",
    "            if discrete_values[i] < min_val or discrete_values[i] > max_val:\n",
    "                return False\n",
    "        \n",
    "        if sum(discrete_values) == 0:\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "boundaries = {'real': [(1, 100_000), (1, 100_000)], 'discrete': [(0, 1) for _ in range(len(X.columns))]}\n",
    "uci_data = UCI(X, y, boundaries)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "451c125b08f5a3f8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def run_gsa(chaotic_constant: bool=False,\n",
    "            repair_solution: bool=False,\n",
    "            runs: int=10,\n",
    "            population_size: int=5,\n",
    "            iterations: int=20\n",
    "            ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    global_train_hist = pd.DataFrame()\n",
    "    global_test_hist = pd.DataFrame(columns=[\"run\", \"accuracy\", \"fitness\", \"TP\", \"FP\", \"TN\", \"FN\"])\n",
    "    \n",
    "    for k in range(runs):\n",
    "        uci_data = UCI(X, y, boundaries)\n",
    "\n",
    "        gsa_algo = GSA(objective_function = uci_data.get_fitness,\n",
    "                       is_feasible=uci_data.is_feasible,\n",
    "                       r_dim=2,\n",
    "                       d_dim=len(X.columns),\n",
    "                       boundaries=uci_data.boundaries)\n",
    "        \n",
    "        training_history = gsa_algo.optimize(population_size=population_size,\n",
    "                                             iters=iterations,\n",
    "                                             chaotic_constant=chaotic_constant,\n",
    "                                             repair_solution=repair_solution)\n",
    "        \n",
    "        training_history.insert(0, \"run\", k)\n",
    "        global_train_hist = pd.concat([global_train_hist, training_history], axis=0)\n",
    "        \n",
    "        print(gsa_algo.solution_history[-1])\n",
    "        fitness, accuracy = uci_data.get_fitness(solution=gsa_algo.solution_history[-1],\n",
    "                                            data=(uci_data.X_test, uci_data.y_test),\n",
    "                                            show_confusion_matrix=True)\n",
    "        \n",
    "        global_test_hist.loc[len(global_test_hist)] = [k, accuracy, fitness, conf_matrix_dict[\"TP\"], conf_matrix_dict[\"FP\"], conf_matrix_dict[\"TN\"], conf_matrix_dict[\"FN\"]]\n",
    "        \n",
    "        print(\"Test accuracy: \", accuracy, \" - Fitness: \", fitness)\n",
    "    \n",
    "    return global_train_hist, global_test_hist\n",
    "    \n",
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "for chaotic_constant in [True, False]:\n",
    "    print(f\"Running GSA with chaotic constant: \", chaotic_constant)\n",
    "    tr_df, tt_df = run_gsa(uci_data,\n",
    "                               chaotic_constant=chaotic_constant,\n",
    "                               runs=10,\n",
    "                               population_size=5,\n",
    "                               iterations=20)\n",
    "    \n",
    "    tr_df[\"chaotic_constant\"] = chaotic_constant\n",
    "    tt_df[\"chaotic_constant\"] = chaotic_constant\n",
    "    train_df = pd.concat([train_df, tr_df], axis=0)\n",
    "    test_df = pd.concat([test_df, tt_df], axis=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f054a60e488b2e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.set_title(\"Fitness\", fontweight='bold')\n",
    "\n",
    "# ax.set_ylim(min(global_train_hist[\"Fitness\"]), max(global_train_hist[\"Fitness\"]))\n",
    "    \n",
    "sns.lineplot(ax=ax,\n",
    "             data=train_df,\n",
    "             x=\"Iteration\",\n",
    "             y=\"Fitness\",\n",
    "             hue=\"chaotic_constant\",\n",
    "             legend=True)\n",
    "\n",
    "ax.grid(axis='y', color='#A9A9A9', alpha=0.3, zorder=1)\n",
    "\n",
    "ax.set_xlabel(\"Iter.\")\n",
    "ax.set_ylabel(\"Fitness\")\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig(save_path, format='svg', dpi=300, bbox_inches='tight', transparent=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7db492409bad26f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.set_title(\"Accuracy\", fontweight='bold')\n",
    "\n",
    "# ax.set_ylim(min(global_train_hist[\"Fitness\"]), max(global_train_hist[\"Fitness\"]))\n",
    "    \n",
    "sns.lineplot(ax=ax,\n",
    "             data=train_df,\n",
    "             x=\"Iteration\",\n",
    "             y=\"Accuracy\",\n",
    "             hue=\"chaotic_constant\",\n",
    "             legend=True)\n",
    "\n",
    "ax.grid(axis='y', color='#A9A9A9', alpha=0.3, zorder=1)\n",
    "\n",
    "ax.set_xlabel(\"Iter.\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "\n",
    "plt.show()\n",
    "# fig.savefig(save_path, format='svg', dpi=300, bbox_inches='tight', transparent=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2eaf37348c524d8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# T-test results (with and without Chaotic constant)\n",
    "from scipy import stats as st\n",
    "\n",
    "# accuracy history in train_df between chaotic_constant=True and chaotic_constant=False\n",
    "chaotic_constant_true = train_df[train_df[\"chaotic_constant\"] == True][\"Fitness\"]\n",
    "chaotic_constant_false = train_df[train_df[\"chaotic_constant\"] == False][\"Fitness\"]\n",
    "\n",
    "st.ttest_ind(chaotic_constant_true, chaotic_constant_false)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67378f6d183d3d1c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mean_accuracy = np.round(np.mean(gsa_history_dict[\"accuracy_history\"]), 4)\n",
    "std_accuracy = np.round(np.std(gsa_history_dict[\"accuracy_history\"]), 4)\n",
    "\n",
    "print(f\"Mean accuracy: {mean_accuracy} +/- {std_accuracy}\")\n",
    "\n",
    "mean_gamma = np.round(np.mean(gsa_history_dict[\"gamma_history\"]), 4)\n",
    "std_gamma = np.round(np.std(gsa_history_dict[\"gamma_history\"]), 4)\n",
    "\n",
    "print(f\"Mean gamma: {mean_gamma} +/- {std_gamma}\")\n",
    "\n",
    "mean_c = np.round(np.mean(gsa_history_dict[\"c_history\"]), 4)\n",
    "std_c = np.round(np.std(gsa_history_dict[\"c_history\"]), 4)\n",
    "\n",
    "print(f\"Mean C: {mean_c} +/- {std_c}\")\n",
    "\n",
    "mean_n_features = np.rint(np.mean(gsa_history_dict[\"n_features_history\"])).astype(int)\n",
    "std_n_features = np.rint(np.std(gsa_history_dict[\"n_features_history\"])).astype(int)\n",
    "\n",
    "print(f\"Mean n_features: {mean_n_features} +/- {std_n_features}\")\n",
    "\n",
    "mean_execution_time = np.round(np.mean(gsa_history_dict[\"execution_time_history\"]), 4)\n",
    "std_execution_time = np.round(np.std(gsa_history_dict[\"execution_time_history\"]), 4)\n",
    "\n",
    "print(f\"Mean execution time: {mean_execution_time} +/- {std_execution_time}\")\n",
    "\n",
    "mean_TP = np.rint(np.mean(gsa_history_dict[\"TP_history\"])).astype(int)\n",
    "std_TP = np.rint(np.std(gsa_history_dict[\"TP_history\"])).astype(int)\n",
    "mean_FP = np.rint(np.mean(gsa_history_dict[\"FP_history\"])).astype(int)\n",
    "std_FP = np.rint(np.std(gsa_history_dict[\"FP_history\"])).astype(int)\n",
    "mean_TN = np.rint(np.mean(gsa_history_dict[\"TN_history\"])).astype(int)\n",
    "std_TN = np.rint(np.std(gsa_history_dict[\"TN_history\"])).astype(int)\n",
    "mean_FN = np.rint(np.mean(gsa_history_dict[\"FN_history\"])).astype(int)\n",
    "std_FN = np.rint(np.std(gsa_history_dict[\"FN_history\"])).astype(int)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "297831f499cee489"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "save_path = \"../data/output\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "    \n",
    "date = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "results = pd.DataFrame({\"date\": [date],\n",
    "                        \"dataset_name\": [widget_opt.value],\n",
    "                        \"r_runs\": [runs],\n",
    "                        \"n_pop\": [population_size],\n",
    "                        \"n_iters\": [iterations],\n",
    "                        \"chaotic_constant\": [chaotic_constant],\n",
    "                        \"repair_solution\": [repair_solution],\n",
    "                        \"execution_time\": [mean_execution_time],\n",
    "                        \"execution_time_std\": [std_execution_time],\n",
    "                        \"wa\": [wa],\n",
    "                        \"wf\": [wf],\n",
    "                        \"mean_accuracy\": [mean_accuracy],\n",
    "                        \"std_accuracy\": [std_accuracy],\n",
    "                        \"mean_gamma\": [mean_gamma],\n",
    "                        \"std_gamma\": [std_gamma],\n",
    "                        \"mean_c\": [mean_c],\n",
    "                        \"std_c\": [std_c],\n",
    "                        \"mean_n_features\": [mean_n_features],\n",
    "                        \"std_n_features\": [std_n_features],\n",
    "                        \"TP\": [mean_TP],\n",
    "                        \"TP_std\": [std_TP],\n",
    "                        \"FP\": [mean_FP],\n",
    "                        \"FP_std\": [std_FP],\n",
    "                        \"TN\": [mean_TN],\n",
    "                        \"TN_std\": [std_TN],\n",
    "                        \"FN\": [mean_FN],\n",
    "                        \"FN_std\": [std_FN]})\n",
    "\n",
    "file = f\"{save_path}/gsa_records.csv\"\n",
    "if os.path.exists(file):\n",
    "    # Load dataframe and append new row\n",
    "    df = pd.read_csv(file)\n",
    "    df = pd.concat([df, results], axis=0, ignore_index=True)\n",
    "    df.to_csv(file, index=False)\n",
    "else: # Append row to existing file\n",
    "    results.to_csv(file, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "443409a31cb91202"
  },
  {
   "cell_type": "markdown",
   "source": [
    "                /\\ \n",
    "               /  \\\n",
    "                || \n",
    "                \n",
    "        Nuestros resultados\n",
    "        \n",
    "Dataset: Mushroom\n",
    "Instances: 8124 (Train / Test: 80% / 20%)\n",
    "Features: 22\n",
    "\n",
    "Resultados autores:\n",
    "\n",
    "| Metric | Value             |\n",
    "| --- |-------------------|\n",
    "| Accuracy | 98.06 +/- 0.78    |\n",
    "| Gamma | 0.0067 +/- 0.0144 |\n",
    "| C | 47.35 +/- 27.57   |\n",
    "| n_features | 3 +/- 2.16        |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7473dc92ea49c9d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "                /\\ \n",
    "               /  \\\n",
    "                || \n",
    "                \n",
    "        Nuestros resultados\n",
    "        \n",
    "Dataset: Breast Cancer Wisconsin (Diagnostic) Data Set\n",
    "\n",
    "Resultados autores:\n",
    "\n",
    "| Metric | Value             |\n",
    "| --- |-------------------|\n",
    "| Accuracy | 99.54 +/- 0.25    |\n",
    "| Gamma | 0.0685 +/- 0.1293 |\n",
    "| C | 40.30 +/- 22.37   |\n",
    "| n_features | 2 +/- 1           |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0b3284064dd5e71"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf875026d9d4f13",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
