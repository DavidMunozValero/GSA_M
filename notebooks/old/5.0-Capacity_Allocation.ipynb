{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Capacity allocation",
   "id": "a024915748d2e717"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Load libraries",
   "id": "14a19a2069976d60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from functools import reduce\n",
    "from mealpy import IntegerVar\n",
    "from mealpy.evolutionary_based import DE, ES, GA\n",
    "from mealpy.physics_based import SA\n",
    "from mealpy.swarm_based import ABC, ACOR, GWO, PSO, WOA\n",
    "from operator import mul\n",
    "from pathlib import Path\n",
    "\n",
    "from benchmarks.generator import get_revenue_behaviour_deprecated\n",
    "from benchmarks.robin_railway import RevenueMaximization\n",
    "from benchmarks.utils import sns_box_plot, sns_line_plot, int_input, get_schedule_from_supply, infer_line_stations, get_services_by_tsp_df, plot_marey_chart\n",
    "\n",
    "from robin.scraping.entities import SupplySaver\n",
    "from robin.services_generator.entities import ServiceGenerator\n",
    "from robin.supply.entities import Supply\n",
    "from src.entities import Solution\n",
    "from src.timetabling_problem import MPTT"
   ],
   "id": "7e3fbf5fe89da215"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Config files\n",
    "supply_config_path = Path(\"../../configs/generator/supply_config.yml\")\n",
    "demand_config_path = Path(\"../../configs/demand/demand.yml\")\n",
    "generator_config_path = Path(\"../../configs/generator/generator_config.yml\")\n",
    "\n",
    "# Save paths\n",
    "generator_save_path = Path(f'../../data/generator/supply_dummy.yml')\n",
    "supply_save_path = '../../configs/mealpy/'\n",
    "robin_save_path = '../../data/output/robin/'\n",
    "figures = '../figures/'\n",
    "\n",
    "# Clean save paths directories\n",
    "if Path(generator_save_path.parent).exists():\n",
    "    shutil.rmtree(generator_save_path.parent)\n",
    "\n",
    "Path(generator_save_path.parent).mkdir(parents=True)\n",
    "\n",
    "if Path(supply_save_path).exists():\n",
    "    shutil.rmtree(supply_save_path)\n",
    "    \n",
    "Path(supply_save_path).mkdir(parents=True)\n",
    "\n",
    "#if Path(figures).exists():\n",
    "#    shutil.rmtree(figures)\n",
    "#Path(figures).mkdir(parents=True)"
   ],
   "id": "33812ace746317fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "seed = 21\n",
    "\n",
    "if generator_config_path:\n",
    "    n_services = int_input(\"Number of services to generate: \")\n",
    "    generator = ServiceGenerator(supply_config_path=supply_config_path)\n",
    "    _ = generator.generate(file_name=generator_save_path,\n",
    "                           path_config=generator_config_path,\n",
    "                           n_services=n_services,\n",
    "                           seed=seed)\n",
    "    print(f'Number of service requests generated: {len(_)}')"
   ],
   "id": "6200410db9e300f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "supply = Supply.from_yaml(generator_save_path)\n",
    "tsp_df = get_services_by_tsp_df(supply.services)\n",
    "\n",
    "print(tsp_df)"
   ],
   "id": "d5849d163a47632d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Services: \", len(supply.services))\n",
    "requested_schedule = get_schedule_from_supply(generator_save_path)\n",
    "revenue_behaviour = get_revenue_behaviour_deprecated(supply)\n",
    "lines = supply.lines\n",
    "line = infer_line_stations(lines)"
   ],
   "id": "b58471bd66954fed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_marey_chart(requested_supply=supply,\n",
    "                 colors_by_tsp=True,\n",
    "                 main_title=\"Marey chart - 25 requests\",\n",
    "                 plot_security_gaps=True,\n",
    "                 security_gap=10,\n",
    "                 save_path=Path('../../reports/mealpy/marey_chart_requests_25.pdf'))"
   ],
   "id": "d9d2b11871ae2303"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Mealpy",
   "id": "5970126fa4152570"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mptt = MPTT(requested_schedule=requested_schedule,\n",
    "            revenue_behaviour=revenue_behaviour,\n",
    "            line=line,\n",
    "            safe_headway=10)"
   ],
   "id": "4df54965b22c6fc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mp_algos = {\"Genetic Algorithm\": GA.BaseGA,\n",
    "            \"Particle Swarm Optimization\": PSO.OriginalPSO,\n",
    "            \"Simulated Annealing\": SA.OriginalSA,\n",
    "            \"Differential Evolution\": DE.OriginalDE,\n",
    "            \"Ant Colony Optimization Continuous (ACOR)\": ACOR.OriginalACOR,\n",
    "            \"Covariance Matrix Adaptation Evolution Strategy\": ES.CMA_ES,\n",
    "            \"Artificial Bee Colony\": ABC.OriginalABC,\n",
    "            \"Grey Wolf Optimizer\": GWO.OriginalGWO,\n",
    "            \"Whale Optimization Algorithm\": WOA.OriginalWOA,\n",
    "            \"Hybrid Grey Wolf - Whale Optimization Algorithm\": GWO.GWO_WOA}"
   ],
   "id": "3b8a6ab9796fbed6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "opti_params = {\"Genetic Algorithm\": {\"epoch\": 500, \"pop_size\": 70},\n",
    "               \"Particle Swarm Optimization\": {\"epoch\": 500, \"pop_size\": 80},\n",
    "               \"Simulated Annealing\": {\"epoch\": 500, \"pop_size\": 90},\n",
    "               \"Differential Evolution\": {\"epoch\": 300, \"pop_size\": 100},\n",
    "               \"Ant Colony Optimization Continuous (ACOR)\": {\"epoch\": 500, \"pop_size\": 10},\n",
    "               \"Covariance Matrix Adaptation Evolution Strategy\": {\"epoch\": 250, \"pop_size\": 80},\n",
    "               \"Artificial Bee Colony\": {\"epoch\": 450, \"pop_size\": 60},\n",
    "               \"Grey Wolf Optimizer\": {\"epoch\": 500, \"pop_size\": 100},\n",
    "               \"Whale Optimization Algorithm\": {\"epoch\": 400, \"pop_size\": 80},\n",
    "               \"Hybrid Grey Wolf - Whale Optimization Algorithm\": {\"epoch\": 450, \"pop_size\": 50}\n",
    "               }"
   ],
   "id": "6878084f4c9a9f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "max_pop_size = max([opti_params[algo][\"pop_size\"] for algo in opti_params])\n",
    "\n",
    "runs = 5\n",
    "seed_initializer = 29\n",
    "\n",
    "# 0. Problem formulation\n",
    "lb, ub = zip(*mptt.boundaries.real)\n",
    "\n",
    "problem = {\"obj_func\": mptt.objective_function,\n",
    "           \"bounds\": IntegerVar(lb=lb,\n",
    "                              ub=ub),\n",
    "           \"minmax\": \"max\",\n",
    "           \"save_population\": True}\n",
    "\n",
    "# Configuración de archivos CSV\n",
    "history_csv = 'history_results.csv'\n",
    "population_csv = 'population_results.csv'\n",
    "\n",
    "# Crear archivos CSV con encabezados si no existen\n",
    "if not os.path.exists(history_csv):\n",
    "    pd.DataFrame(columns=['Run', 'Algo', 'Iteration', 'Fitness', 'ExecutionTime', 'Discrete', \n",
    "                          'Real', 'Diversity', 'Exploitation', 'Exploration']\n",
    "                 ).to_csv(history_csv, sep=';', index=False)\n",
    "\n",
    "if not os.path.exists(population_csv):\n",
    "    population_columns = ['Run', 'Algo', 'Iteration'] + \\\n",
    "                         [f'real_{i}' for i in range(max_pop_size)] + \\\n",
    "                         [f'discrete_{i}' for i in range(max_pop_size)]\n",
    "    pd.DataFrame(columns=population_columns).to_csv(population_csv, sep=';' , index=False)\n",
    "\n",
    "# Ejecución principal\n",
    "for algo_name, algo in mp_algos.items():\n",
    "    \n",
    "    # Re-inicializar semilla\n",
    "    np.random.seed(seed_initializer)\n",
    "    \n",
    "    print(f\"Running {algo_name}\")\n",
    "    for r in range(1, runs+1):\n",
    "        print(\"\\tRun: \", r)\n",
    "        \n",
    "        run_seed = np.random.randint(0, 1000)\n",
    "        \n",
    "        # Ejecutar algoritmo\n",
    "        if algo_name == \"Simulated Annealing\":\n",
    "            optimizer = algo(reduce(mul, opti_params[algo_name].values()))\n",
    "            optimizer.solve(problem, seed=run_seed)\n",
    "        else:\n",
    "            optimizer = algo(**opti_params[algo_name])\n",
    "            optimizer.solve(problem, seed=run_seed)\n",
    "            \n",
    "        # Guardar historial\n",
    "        run_history = []\n",
    "        for i, data in enumerate(optimizer.history.list_global_best):\n",
    "            mptt.update_schedule(data.solution)\n",
    "            run_history.append([\n",
    "                r, algo_name, i, data.target.fitness, optimizer.history.list_epoch_time[i], \n",
    "                mptt.get_heuristic_schedule(), data.solution, \n",
    "                optimizer.history.list_diversity[i], optimizer.history.list_exploitation[i], \n",
    "                optimizer.history.list_exploration[i]\n",
    "            ])\n",
    "        \n",
    "        # Guardar en CSV\n",
    "        pd.DataFrame(run_history, columns=['Run', 'Algo', 'Iteration', 'Fitness', 'ExecutionTime', \n",
    "                                           'Discrete', 'Real', 'Diversity', 'Exploitation', 'Exploration']\n",
    "                    ).to_csv(history_csv, sep=';', mode='a', header=False, index=False)\n",
    "        \n",
    "        # Guardar población\n",
    "        if algo_name == \"Simulated Annealing\":\n",
    "            continue\n",
    "        \n",
    "        run_population = []\n",
    "        for i, pop_epoch in enumerate(optimizer.history.list_population):\n",
    "            real = []\n",
    "            discrete = []\n",
    "            for individual in pop_epoch:\n",
    "                mptt.update_schedule(individual.solution)\n",
    "                real.append(individual.solution)\n",
    "                discrete.append(mptt.get_heuristic_schedule())\n",
    "            \n",
    "            if len(real) < max_pop_size:\n",
    "                real += [np.nan] * (max_pop_size - len(real))\n",
    "                discrete += [np.nan] * (max_pop_size - len(discrete))\n",
    "                \n",
    "            run_population.append([r, algo_name, i, *real, *discrete])\n",
    "        \n",
    "        # Guardar en CSV\n",
    "        population_columns = ['Run', 'Algo', 'Iteration'] + \\\n",
    "                             [f'real_{i}' for i in range(max_pop_size)] + \\\n",
    "                             [f'discrete_{i}' for i in range(max_pop_size)]\n",
    "        \n",
    "        pd.DataFrame(run_population, columns=population_columns).to_csv(population_csv, sep=';', mode='a', header=False, index=False) "
   ],
   "id": "f124e142b56e9963"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Results analysis",
   "id": "8d3be97d095c1ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_history_old = pd.read_csv('../../reports/mealpy_untracked/df_history_5_seed.csv', sep=\";\")\n",
    "\n"
   ],
   "id": "6f973b5fc0cac169"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_history = pd.read_csv('../history_results.csv', sep=\";\")",
   "id": "3c3381801752508a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_population = pd.read_csv('../population_results.csv', sep=\";\", low_memory=False)",
   "id": "77b3d4dae12d45b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def transform_columns(df):\n",
    "    columns_to_transform = df.filter(like=\"Real\").columns\n",
    "\n",
    "    df[columns_to_transform] = df[columns_to_transform].apply(\n",
    "        lambda col: col.map(lambda x: np.array(list(map(float, x[1:-1].split())), dtype=np.int32))\n",
    "    )\n",
    "\n",
    "    columns_to_transform = df.filter(like=\"Discrete\").columns\n",
    "\n",
    "    df[columns_to_transform] = df[columns_to_transform].apply(\n",
    "        lambda col: col.map(lambda x: np.array(list(map(lambda s: True if s == \"True\" else False, x[1:-1].split())), dtype=bool))\n",
    "    )\n",
    "\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "df_history_old = transform_columns(df_history_old)"
   ],
   "id": "4d4d9c06d3835041"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_history = transform_columns(df_history)",
   "id": "6868707abfb1446d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_population.head()",
   "id": "7ceefc96b79bd00b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "columns_to_transform = df_population.filter(like=\"real_\").columns\n",
    "\n",
    "def converter(x):\n",
    "    if isinstance(x, str):\n",
    "        return np.array(list(map(float, x[1:-1].split())), dtype=np.int32)\n",
    "    elif isinstance(x, float):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return list(map(float, x))\n",
    "    \n",
    "df_population[columns_to_transform] = df_population[columns_to_transform].apply(\n",
    "    lambda col: col.map(converter)\n",
    ")\n",
    "\n",
    "df_population.head()"
   ],
   "id": "a790107ca60f7523"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.timetabling_problem import MPTT\n",
    "\n",
    "# Define new revenue maximization object for results analysis\n",
    "mptt = MPTT(requested_schedule=requested_schedule,\n",
    "            revenue_behaviour=revenue_behaviour,\n",
    "            line=line,\n",
    "            safe_headway=10)\n",
    "\n",
    "top_3_algos = (\"Genetic Algorithm\",\n",
    "               \"Ant Colony Optimization Continuous (ACOR)\",\n",
    "               \"Differential Evolution\")\n",
    "\n",
    "# Create dataframe with fitness values for each individual of the population\n",
    "df_pop = df_population[df_population['Algo'].isin(top_3_algos)]\n",
    "\n",
    "set_filtered_algos = set(df_pop[\"Algo\"])\n",
    "print(f\"Filtered algos: {set_filtered_algos}\")\n",
    "\n",
    "df_pop = df_pop.replace(r'\\n', ' ', regex=True)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_pop.drop(columns=[col for col in df_pop.columns if 'discrete' in col], inplace=True)\n",
    "\n",
    "# Function to compute fitness\n",
    "def fitness_from_real(x: np.array) -> float:\n",
    "    if isinstance(x, float):\n",
    "        return np.nan\n",
    "    return mptt.objective_function(x)\n",
    "\n",
    "# Iterate through the dataframe and apply the function with progress feedback\n",
    "real_columns = df_pop.columns[df_pop.columns.str.contains('real_')]\n",
    "previous_run, previous_algo = None, None\n",
    "\n",
    "for index, row in df_pop.iterrows():\n",
    "    current_run = row['Run']\n",
    "    current_algo = row['Algo']\n",
    "\n",
    "    # Print message if there's a change in 'Run' or 'Algo'\n",
    "    if current_run != previous_run or current_algo != previous_algo:\n",
    "        print(f\"Processing new combination: Run = {current_run}, Algo = {current_algo}\")\n",
    "        previous_run, previous_algo = current_run, current_algo\n",
    "\n",
    "    # Apply the fitness function to the real columns\n",
    "    df_pop.loc[index, real_columns] = row[real_columns].map(fitness_from_real)\n",
    "\n",
    "print(\"Processing completed.\")\n",
    "df_pop"
   ],
   "id": "8c75e469d2ac80f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save df_pop\n",
    "df_pop.to_csv('df_pop_5_opti_fit_top3_GA_ACOR_DE.csv', sep=\";\", index=False)"
   ],
   "id": "57b5d90a02a50cf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prepare dataframe for boxplot\n",
    "rows = []\n",
    "for row in df_pop.iterrows():\n",
    "    run = row[1]['Run']\n",
    "    iteration = row[1]['Iteration']\n",
    "    algo = row[1]['Algo']\n",
    "    \n",
    "    for individual in [ind_name for ind_name in row[1].index if 'real_' in ind_name]:\n",
    "        fitness = row[1][individual]\n",
    "        if not np.isnan(fitness):\n",
    "            rows.append({'Run': run, 'Iteration': iteration, 'Fitness': fitness, 'Algorithm': algo, 'Individual': f'ID_{individual}'})\n",
    "        \n",
    "df_boxplot = pd.DataFrame.from_dict(rows, orient='columns')\n",
    "df_boxplot"
   ],
   "id": "d5713b6b6d1b052a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Filter df, only rows with 'Iteration' values included in [0, .., 49]\n",
    "df_boxplot_filtered = df_boxplot[df_boxplot['Iteration'].isin([0, 99, 199, 299, 399, 499])]\n",
    "\n",
    "# Sum 1 to each value in 'Iteration' column\n",
    "df_boxplot_filtered['Iteration'] = df_boxplot_filtered['Iteration'] + 1\n",
    "\n",
    "sns_box_plot(df=df_boxplot_filtered,\n",
    "             x_data='Iteration',\n",
    "             y_data='Fitness',\n",
    "             hue='Algorithm',\n",
    "             title=\"Scattered Boxplot of Population for Top 3 Algorithms\",\n",
    "             x_label=\"Epoch\",\n",
    "             y_label=\"Fitness (Revenue)\",\n",
    "             save_path=Path('../../reports/mealpy/scattered_boxplot_top_3_25_opti_new.pdf'))"
   ],
   "id": "c069984e16f2cc95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Table with results by run\n",
    "\n",
    "sm = RevenueMaximization(requested_schedule=requested_schedule,\n",
    "                         revenue_behaviour=revenue_behaviour,\n",
    "                         line=line,\n",
    "                         safe_headway=10)\n",
    "\n",
    "service_tsps = {service.id: service.tsp.name for service in supply.services}\n",
    "columns = ['Algorithm', 'Run', 'Revenue', 'Execution Time (s.)', 'Scheduled Trains', 'Delta DT (min.)', 'Delta TT (min.)']\n",
    "columns += set(service_tsps.values())\n",
    "\n",
    "summary_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "algo_grouped_df = df_history.groupby('Algo')\n",
    "\n",
    "for algo_group in algo_grouped_df:\n",
    "    run_grouped_df = algo_group[1].groupby('Run')\n",
    "    for group in run_grouped_df.groups:\n",
    "        run = run_grouped_df.get_group(group)['Run'].iloc[-1]\n",
    "        revenue = np.round(run_grouped_df.get_group(group)['Fitness'].iloc[-1], 2)\n",
    "        execution_time = np.round(run_grouped_df.get_group(group)['ExecutionTime'].sum(), 2)\n",
    "        scheduled_trains_array = run_grouped_df.get_group(group)['Discrete'].iloc[-1]\n",
    "        scheduled_trains = int(sum(run_grouped_df.get_group(group)['Discrete'].iloc[-1]))\n",
    "        real_solution = run_grouped_df.get_group(group)['Real'].iloc[-1]\n",
    "        sm.update_schedule(Solution(real=real_solution, discrete=scheduled_trains))\n",
    "        delta_dt = 0.0\n",
    "        delta_tt = 0.0\n",
    "        services_by_tsp = {tsp: 0 for tsp in service_tsps.values()}\n",
    "        for i, service in enumerate(sm.requested_schedule):\n",
    "            if not scheduled_trains_array[i]:\n",
    "                continue\n",
    "            departure_station = list(sm.requested_schedule[service].keys())[0]\n",
    "            delta_dt += abs(sm.updated_schedule[service][departure_station][1] -\n",
    "                            sm.requested_schedule[service][departure_station][1])\n",
    "            for j, stop in enumerate(sm.requested_schedule[service].keys()):\n",
    "                if j == 0 or j == len(sm.requested_schedule[service]) - 1:\n",
    "                    continue\n",
    "                delta_tt += abs(sm.updated_schedule[service][stop][1] - sm.requested_schedule[service][stop][1])\n",
    "    \n",
    "            service_tsp = service_tsps[service]\n",
    "            services_by_tsp[service_tsp] += 1\n",
    "    \n",
    "        percentages_by_tsp = {}\n",
    "        for tsp in services_by_tsp:\n",
    "            percentages_by_tsp[tsp] = f\"{np.round(services_by_tsp[tsp] / tsp_df.loc[tsp, 'Number of Services'] * 100, 2)} %\"\n",
    "        row_data =  [algo_group[0], run, revenue, execution_time, \n",
    "                     scheduled_trains, np.round(delta_dt, 2), np.round(delta_tt, 2), *list(percentages_by_tsp.values())]\n",
    "        summary_df.loc[len(summary_df)] = row_data\n",
    "\n",
    "summary_df = summary_df.sort_values('Revenue', ascending=False)\n",
    "display(summary_df)\n",
    "print()"
   ],
   "id": "f481a830acda934"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "summary_df.to_latex()",
   "id": "a6e2c3beaa3aee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Global status\n",
    "\n",
    "def get_global_status(df: pd.DataFrame):\n",
    "    algo_grouped_df = df.groupby('Algo')\n",
    "\n",
    "    for algo_group in algo_grouped_df:\n",
    "        run_grouped_df = algo_group[1].groupby('Run')\n",
    "        \n",
    "        print(f\"Global {algo_group[0]} status:\")\n",
    "        \n",
    "        # Execution time (mean and std.)\n",
    "        run_times = run_grouped_df['ExecutionTime'].last()\n",
    "        print(f'\\tTotal execution time: {round(run_times.sum(), 4)} s.')\n",
    "        print(f'\\tExecution Time (by run) - Mean: {round(run_times.mean(), 4)} s. - Std: {round(run_times.std(), 4)} s.')\n",
    "        \n",
    "        # Revenue (mean and std.)\n",
    "        run_revenues = run_grouped_df['Fitness'].last()\n",
    "        print(f'\\tRevenue - Mean: {round(run_revenues.mean(), 4)} - Std: {round(run_revenues.std(), 4)}')\n",
    "        \n",
    "        # Scheduled trains (mean and std.)\n",
    "        run_trains = run_grouped_df['Discrete'].last().apply(sum)\n",
    "        print(f'\\tScheduled Trains - Mean: {np.round(run_trains.mean())} - Std: {np.round(run_trains.std())}')\n",
    "        \n",
    "        max_revenue = sum([sm.revenue[service]['canon'] for service in sm.revenue])\n",
    "        print(f\"\\tMax Revenue: {max_revenue} - WARNING!: Scheduling all services could not be feasible\")\n",
    "        print()\n",
    "        \n",
    "get_global_status(df_history)"
   ],
   "id": "6b6a4bc5b45c1c2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def get_global_status_as_dataframe(df: pd.DataFrame):\n",
    "    algo_grouped_df = df.groupby('Algo')\n",
    "    \n",
    "    results = []\n",
    "    for algo_name, algo_group in algo_grouped_df:\n",
    "        run_grouped_df = algo_group.groupby('Run')\n",
    "        \n",
    "        run_times = run_grouped_df['ExecutionTime'].sum()\n",
    "        \n",
    "        run_revenues = run_grouped_df['Fitness'].last()\n",
    "        run_trains = run_grouped_df['Discrete'].last().apply(sum)\n",
    "        \n",
    "        result = {\n",
    "            'Algorithm': algo_name,\n",
    "            'Mean Execution Time (seconds)': round(run_times.mean(), 2),\n",
    "            'Std Execution Time (seconds)': round(run_times.std(), 2),\n",
    "            'Mean Fitness (revenue)': round(run_revenues.mean(), 2),\n",
    "            'Std Fitness (revenue)': round(run_revenues.std(), 2),\n",
    "            'Mean Scheduled Trains': int(round(run_trains.mean())),\n",
    "            'Std Scheduled Trains': int(round(run_trains.std()))\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Short by column 'Mean Fitness' \n",
    "    results_df = results_df.sort_values(by='Mean Fitness (revenue)', ascending=False).reset_index(drop=True)\n",
    "    return results_df\n",
    "\n",
    "results_df = get_global_status_as_dataframe(df_history)\n",
    "results_df"
   ],
   "id": "395d3f4c188645b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "results_df.to_latex()",
   "id": "ad6949363c845860"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_history_copy = df_history.copy()\n",
    "\n",
    "df_history['Iteration'] = df_history['Iteration'] + 1\n",
    "\n",
    "sns_line_plot(df=df_history,\n",
    "              x_data=\"Iteration\",\n",
    "              y_data=\"Fitness\",\n",
    "              hue=\"Algo\",\n",
    "              title=\"Convergence curves - Optimized hiperparameters\",  # Título: Curvas de convergencia - Hiperparámetros optimizados\n",
    "              x_label=\"Epoch\",\n",
    "              y_label=\"Fitness (Revenue)\",\n",
    "              x_limit=(-1, 500),\n",
    "              y_limit=(1500,4600),\n",
    "              save_path=Path('../../reports/mealpy/mealpy_convergence_5_opti.pdf'),\n",
    "              fig_size=(10, 9))"
   ],
   "id": "ef4ab994c32bf730"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "top_3_algos = (\"Genetic Algorithm\",\n",
    "               \"Ant Colony Optimization Continuous (ACOR)\",\n",
    "               \"Differential Evolution\")\n",
    "\n",
    "# Create dataframe with fitness values for each individual of the population\n",
    "df_history_top_3 = df_history[df_history['Algo'].isin(top_3_algos)]\n",
    "\n",
    "df_history_top_3['Iteration'] = df_history_top_3['Iteration'] + 1\n",
    "\n",
    "sns_line_plot(df=df_history_top_3,\n",
    "              x_data=\"Iteration\",\n",
    "              y_data=\"Fitness\",\n",
    "              hue=\"Algo\",\n",
    "              title=\"Convergence curves - Top 3 Algorithms, Optimized hiperparameters\",\n",
    "              x_label=\"Epoch\",\n",
    "              y_label=\"Fitness (Revenue)\",\n",
    "              x_limit=(0, 500),\n",
    "              y_limit=(2100,4600),\n",
    "              legend_type=\"\",\n",
    "              save_path=Path('../../reports/mealpy/mealpy_convergence_5_opti_top_3.pdf'),\n",
    "              fig_size=(10, 7))"
   ],
   "id": "2413ea20bba6522b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_history.head()",
   "id": "3b3c9e9ed961c1cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "N = 50  # Número de saltos que quieres aplicar\n",
    "\n",
    "algo_1_vals = df_history[df_history['Algo'] == 'Simulated Annealing'] \\\n",
    "    .groupby(['Run', 'Iteration'])['Fitness'].last() \\\n",
    "    .groupby(level='Run').apply(lambda x: x.iloc[::N].tolist()).sum()\n",
    "\n",
    "algo_1_vals"
   ],
   "id": "a7d6d76ce9e53c3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "algo_df = df_history[df_history['Algo'] == 'Genetic Algorithm']\n",
    "\n",
    "algo_vals = algo_df.groupby(['Iteration'])['Fitness'].max().tolist()\n",
    "\n",
    "algo_vals"
   ],
   "id": "ba03f349c0b7ba85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(len(algo_vals))",
   "id": "730f1489fe547136"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "algo_df = df_history[df_history['Algo'] == 'Simulated Annealing']\n",
    "\n",
    "N = 50\n",
    "algo_vals = algo_df.groupby(algo_df['Iteration'] // N)['Fitness'].max().tolist()\n",
    "\n",
    "algo_vals"
   ],
   "id": "b46a4067c4711f6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(len(algo_vals))",
   "id": "1c834e0e53be0465"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def recortar_listas(lista1, lista2):\n",
    "    # Convertir a arrays de numpy\n",
    "    arr1 = np.array(lista1)\n",
    "    arr2 = np.array(lista2)\n",
    "    \n",
    "    # Encontrar índices donde aparecen np.nan\n",
    "    nan_idx1 = np.where(np.isnan(arr1))[0]\n",
    "    nan_idx2 = np.where(np.isnan(arr2))[0]\n",
    "    \n",
    "    # Determinar la posición mínima de np.nan\n",
    "    min_idx = min(\n",
    "        nan_idx1[0] if len(nan_idx1) > 0 else len(arr1),\n",
    "        nan_idx2[0] if len(nan_idx2) > 0 else len(arr2)\n",
    "    )\n",
    "    \n",
    "    # Recortar las listas\n",
    "    return arr1[:min_idx].tolist(), arr2[:min_idx].tolist()\n",
    "\n",
    "# Ejemplo de uso\n",
    "lista1 = [1.0, 2, 3, 4]\n",
    "lista2 = [5, 6, np.nan, np.nan]\n",
    "\n",
    "recortada1, recortada2 = recortar_listas(lista1, lista2)\n",
    "print(recortada1, recortada2)"
   ],
   "id": "7a04db375bac1ba0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Confusion Matrix stadistical differences \n",
    "\n",
    "N = 50\n",
    "from scipy import stats\n",
    "\n",
    "def get_epoch_last_fitness(df, name):\n",
    "    algo_df = df[df['Algo'] == name]\n",
    "    if name != 'Simulated Annealing':\n",
    "        algo_vals = algo_df.groupby(['Run', 'Iteration'])['Fitness'].last().groupby(level='Run').apply(list).sum()\n",
    "    else:\n",
    "        algo_vals = algo_df.groupby(['Run', 'Iteration'])['Fitness'].last().groupby(level='Run').apply(lambda x: x.iloc[::N].tolist()).sum()\n",
    "    return algo_vals\n",
    "\n",
    "def get_epoch_best_fitness(df, name):\n",
    "    algo_df = df[df['Algo'] == name]\n",
    "    if name != 'Simulated Annealing':\n",
    "        algo_vals = algo_df.groupby(['Iteration'])['Fitness'].max().tolist()\n",
    "    else:\n",
    "        algo_vals = algo_df.groupby(algo_df['Iteration'] // N)['Fitness'].max().tolist()\n",
    "    return algo_vals\n",
    "\n",
    "def get_run_best_fitness(df, name):\n",
    "    algo_df = df[df['Algo'] == name]\n",
    "    algo_vals = algo_df.groupby(['Run'])['Fitness'].max().tolist()\n",
    "    return algo_vals\n",
    "\n",
    "matrix_wilcoxon = []\n",
    "matrix_p_values = []\n",
    "for algo_name, algo in mp_algos.items():\n",
    "    row_w = []\n",
    "    row_p = []\n",
    "    for algo_name_2, algo_2 in mp_algos.items():\n",
    "        if algo_name == algo_name_2:\n",
    "            row_w.append(np.nan)\n",
    "            row_p.append(np.nan)\n",
    "            continue\n",
    "        \n",
    "        algo_1_vals = get_run_best_fitness(df_history, algo_name)\n",
    "        algo_2_vals = get_run_best_fitness(df_history, algo_name_2)\n",
    "        stat, p_value = stats.kstest(algo_1_vals, algo_2_vals)\n",
    "        row_w.append(round(stat))\n",
    "        row_p.append(round(p_value, 3))\n",
    "    matrix_wilcoxon.append(row_w)\n",
    "    matrix_p_values.append(row_p)"
   ],
   "id": "64a74f81c56d9266"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"Wilcoxon Matrix\")\n",
    "df_wilcoxon = pd.DataFrame(matrix_wilcoxon, index=mp_algos.keys(), columns=mp_algos.keys())\n",
    "print(df_wilcoxon)"
   ],
   "id": "6b1944cb7a7c9b6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"P-Values Matrix\")\n",
    "df_p_values = pd.DataFrame(matrix_p_values, index=mp_algos.keys(), columns=mp_algos.keys())\n",
    "print(df_p_values)"
   ],
   "id": "9e961d5b0af8274c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(df_wilcoxon, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar(label='Statistical difference')\n",
    "plt.xticks(range(10), df_wilcoxon.columns, rotation=30, ha='right')\n",
    "plt.yticks(range(10), df_wilcoxon.index)\n",
    "plt.title('Confusion Matrix - Wilcoxon Statistic', fontweight='bold', fontsize=18)\n",
    "\n",
    "for i in range(df_wilcoxon.shape[0]):\n",
    "    for j in range(df_wilcoxon.shape[1]):\n",
    "        value = df_wilcoxon.iloc[i, j]\n",
    "        if np.isnan(value):\n",
    "            # Manejo especial para NaN\n",
    "            display_value = \"NaN\"\n",
    "            text_color = 'white'  # Color negro para NaN\n",
    "            rect_color = (0.2, 0.2, 0.2)  # Gris oscuro\n",
    "            plt.gca().add_patch(plt.Rectangle((j - 0.5, i - 0.5), 1, 1, color=rect_color))\n",
    "        else:\n",
    "            display_value = f\"{int(value)}\"\n",
    "            text_color = 'black' if value > 50000 else 'white'\n",
    "        \n",
    "        plt.text(j, i, display_value, ha='center', va='center', color=text_color)\n",
    "        \n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(-0.5, 10, 1), minor=True)\n",
    "ax.set_yticks(np.arange(-0.5, 10, 1), minor=True)\n",
    "ax.grid(which=\"minor\", color='gray', linestyle='-', linewidth=0.5)\n",
    "ax.tick_params(which=\"minor\", size=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/wilcoxon_confusion_matrix_5_seed_opti_df_history.pdf\", format='pdf', dpi=300, bbox_inches='tight', transparent=True)\n",
    "\n",
    "plt.show()"
   ],
   "id": "3db0d773347a1fae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualización con matplotlib\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(df_p_values, cmap='viridis', vmin=0, vmax=1, interpolation='nearest')\n",
    "plt.colorbar(label='Statistical difference')\n",
    "plt.xticks(range(10), df_p_values.columns, rotation=30, ha='right')\n",
    "plt.yticks(range(10), df_p_values.index)\n",
    "plt.title('Confusion Matrix - P-values', fontweight='bold', fontsize=18)\n",
    "\n",
    "for i in range(df_p_values.shape[0]):\n",
    "    for j in range(df_p_values.shape[1]):\n",
    "        value = df_p_values.iloc[i, j]\n",
    "        if np.isnan(value):\n",
    "            # Manejo especial para NaN\n",
    "            display_value = \"NaN\"\n",
    "            text_color = 'white'  # Color negro para NaN\n",
    "            rect_color = (0.2, 0.2, 0.2)  # Gris oscuro\n",
    "            plt.gca().add_patch(plt.Rectangle((j - 0.5, i - 0.5), 1, 1, color=rect_color))\n",
    "        else:\n",
    "            display_value = f\"{value:.3f}\"\n",
    "            text_color = 'black' if value > 0.4 else 'white'\n",
    "        \n",
    "        plt.text(j, i, display_value, ha='center', va='center', color=text_color)\n",
    "        \n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(-0.5, 10, 1), minor=True)\n",
    "ax.set_yticks(np.arange(-0.5, 10, 1), minor=True)\n",
    "ax.grid(which=\"minor\", color='gray', linestyle='-', linewidth=0.5)\n",
    "ax.tick_params(which=\"minor\", size=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/p_values_confusion_matrix_5_seed_opti_df_history.pdf\", format='pdf', dpi=300, bbox_inches='tight', transparent=True)\n",
    "\n",
    "plt.show()"
   ],
   "id": "40d4094eaa253b5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "cmap = colors.ListedColormap(['#b3e5b3', '#ffb3b3'])\n",
    "bounds = [0, 0.05, 1]\n",
    "norm = colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "names = [\"GA\", \"PSO\", \"SA\", \"DE\", \"ACOR\", \"CMA-ES\", \"ABC\", \"GWO\", \"WOA\", \"GWO-WOA\"]\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(df_p_values, cmap=cmap, norm=norm, interpolation='nearest')\n",
    "# plt.colorbar(label='P-value', shrink=0.8)\n",
    "plt.xticks(range(df_p_values.shape[1]), names, rotation=35, ha='right', fontsize=14)\n",
    "plt.yticks(range(df_p_values.shape[0]), names, fontsize=14)\n",
    "plt.title('Algorithm Pairwise Comparison: p-Values', fontweight='bold', fontsize=22)\n",
    "\n",
    "for i in range(df_p_values.shape[0]):\n",
    "    for j in range(df_p_values.shape[1]):\n",
    "        value = df_p_values.iloc[i, j]\n",
    "        if np.isnan(value):\n",
    "            display_value = \"NaN\"\n",
    "            text_color = 'white'\n",
    "            rect_color = (0.5, 0.5, 0.5)\n",
    "            plt.gca().add_patch(plt.Rectangle((j - 0.5, i - 0.5), 1, 1, color=rect_color))\n",
    "        else:\n",
    "            display_value = f\"{value:.3f}\"\n",
    "            text_color = 'black'\n",
    "\n",
    "        plt.text(j, i, display_value, ha='center', va='center', color=text_color, fontsize=14)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(-0.5, df_p_values.shape[1], 1), minor=True)\n",
    "ax.set_yticks(np.arange(-0.5, df_p_values.shape[0], 1), minor=True)\n",
    "ax.grid(which=\"minor\", color='gray', linestyle='-', linewidth=0.5)\n",
    "ax.tick_params(which=\"minor\", size=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/p_values_confusion_matrix_improved_opti_df_history.pdf\", format='pdf', dpi=300, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ],
   "id": "329e15d5a972fca6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Confusion Matrix stadistical differences\n",
    "\n",
    "N = 50\n",
    "from scipy import stats\n",
    "\n",
    "def get_run_best_fitness(df, name):\n",
    "    algo_df = df[df['Algo'] == name]\n",
    "    algo_vals = algo_df.groupby(['Run'])['Fitness'].max().tolist()\n",
    "    print(algo_vals)\n",
    "    return algo_vals\n",
    "\n",
    "row_ks = {}\n",
    "row_p_values = {}\n",
    "for algo_name, algo in mp_algos.items():\n",
    "    algo_1_vals = get_run_best_fitness(df_history_old, algo_name)\n",
    "    algo_2_vals = get_run_best_fitness(df_history, algo_name)\n",
    "    stat, p_value = stats.kstest(algo_1_vals, algo_2_vals)\n",
    "    row_ks[algo_name] = round(stat)\n",
    "    row_p_values[algo_name] = round(p_value, 3)\n",
    "\n",
    "print(row_p_values)"
   ],
   "id": "214764ec9481964c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Select a solution from df_history:\n",
    "algo_name = 'Genetic Algorithm'\n",
    "run = 4\n",
    "iteration = 499\n",
    "\n",
    "filtered_row = df_history[\n",
    "    (df_history[\"Algo\"] == algo_name) &\n",
    "    (df_history[\"Run\"] == run) &\n",
    "    (df_history[\"Iteration\"] == iteration)\n",
    "]\n",
    "\n",
    "# Get values from columns \"Real\" & \"Discrete\"\n",
    "if not filtered_row.empty:\n",
    "    real_value = filtered_row[\"Real\"].iloc[0]\n",
    "    discrete_value = filtered_row[\"Discrete\"].iloc[0]\n",
    "    ga_best_sol = Solution(real=real_value, discrete=discrete_value)\n",
    "    print(f\"Real: {real_value}, Discrete: {discrete_value}\")\n",
    "else:\n",
    "    print(\"Row not found matching the provided parameters.\")"
   ],
   "id": "d5b4240d5e3b997d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sm = RevenueMaximization(requested_schedule=requested_schedule,\n",
    "                         revenue_behaviour=revenue_behaviour,\n",
    "                         line=line,\n",
    "                         safe_headway=10)\n",
    "\n",
    "services = sm.update_supply(path=generator_save_path,\n",
    "                            solution=ga_best_sol)\n",
    "\n",
    "sm.update_schedule(solution=ga_best_sol)\n",
    "\n",
    "filtered_services = {}\n",
    "for i, service in enumerate(sm.updated_schedule):\n",
    "    if ga_best_sol.discrete[i]:\n",
    "        filtered_services[service] = sm.updated_schedule[service]\n",
    "\n",
    "#plotter = TrainSchedulePlotter(filtered_services, line)\n",
    "#plotter.plot(plot_security_gaps=True, save_path=Path('../figures/updated.pdf'))\n",
    "\n",
    "tt_file_name = f'{supply_config_path.stem}_mealpy'\n",
    "print(supply_save_path, tt_file_name)\n",
    "SupplySaver(services).to_yaml(filename=f'{tt_file_name}.yml', save_path=supply_save_path)\n",
    "\n",
    "# Copy previous file in reports\n",
    "reports_path = Path('../../reports/mealpy/')\n",
    "shutil.copyfile(f\"{supply_save_path}{tt_file_name}.yml\", reports_path / f'{tt_file_name}_25_mealpy_opti_hiper.yml')\n",
    "\n",
    "supply_config_file = Path(f'{supply_save_path}{tt_file_name}.yml')"
   ],
   "id": "e06278929b19f050"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "final_supply = Supply.from_yaml(supply_config_file)",
   "id": "768a8b773928ebe4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_marey_chart(requested_supply=final_supply,\n",
    "                 colors_by_tsp=True,\n",
    "                 main_title=\"Marey chart - GA solution, 4th run\",\n",
    "                 plot_security_gaps=True,\n",
    "                 security_gap=10,\n",
    "                 save_path=Path('../../reports/mealpy/marey_chart_ga_25_opti_hiper.pdf'))"
   ],
   "id": "92861309d51bb09d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "shutil.copyfile(f\"{supply_save_path}{tt_file_name}.yml\", reports_path / f'mealpy/{tt_file_name}_25.yml')",
   "id": "c562d639b7935d47"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#!snakeviz profile.pstat",
   "id": "734ec37346d306f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a979d14bc614d534"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
